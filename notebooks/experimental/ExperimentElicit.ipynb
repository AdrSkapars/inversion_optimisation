{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for standalone experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env HF_TOKEN="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m122 packages\u001b[0m \u001b[2min 3.09s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m                       \n",
      "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m               \u001b[1A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/105.74 KiB          \u001b[2A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/105.74 KiB          \u001b[2A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.74 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[3A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 46.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 62.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2K\u001b[4A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/128.01 KiB          \u001b[4A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2murllib3             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/128.01 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/315.69 KiB          \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mplatformdirs        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 14.89 KiB/18.29 KiB\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.86 KiB/105.74 KiB\n",
      "\u001b[2murllib3             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/128.01 KiB\n",
      "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0m B/315.69 KiB          \u001b[5A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mclick               \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 94.86 KiB/105.74 KiB\n",
      "\u001b[2murllib3             \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 32.00 KiB/128.01 KiB\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.88 KiB/495.27 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.97 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.12 MiB\n",
      "\u001b[2K\u001b[12A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0mB/21.83 MiB           \u001b[12A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2murllib3             \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 48.00 KiB/128.01 KiB\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.88 KiB/495.27 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.97 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.12 MiB\n",
      "\u001b[2K\u001b[11A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0mB/21.83 MiB           \u001b[11A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2murllib3             \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 79.78 KiB/128.01 KiB\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.00 KiB/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 29.79 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 30.88 KiB/495.27 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0mKiB/21.83 MiB         \u001b[13A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.74 KiB/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 92.44 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.00 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 78.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 63.66 KiB/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 94.88 KiB/495.27 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 64.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 80.00 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 64.00 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 65.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[12A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m transformers-stream-generator\u001b[2m==0.0.5\u001b[0mKiB/21.83 MiB         \u001b[12A\n",
      "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 104.74 KiB/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 188.44 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.00 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.75 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 175.55 KiB/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 286.88 KiB/495.27 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 144.00 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 144.00 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 97.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)------------\u001b[0m\u001b[0m 92.20 KiB/21.83 MiB         \u001b[11A\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 152.74 KiB/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 252.44 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 176.00 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 174.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 239.66 KiB/452.71 KiB\n",
      "\u001b[2msafetensors         \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 495.27 KiB/495.27 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 272.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 231.24 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 295.12 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 177.37 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)------------\u001b[0m\u001b[0m 167.01 KiB/21.83 MiB        \u001b[11A\n",
      "\u001b[2mtransformer-lens    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 152.74 KiB/187.52 KiB\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 252.44 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 191.89 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 190.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 239.66 KiB/452.71 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 288.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 231.24 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 361.59 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 177.37 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)------------\u001b[0m\u001b[0m 183.01 KiB/21.83 MiB        \u001b[10A\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 315.69 KiB/315.69 KiB\n",
      "\u001b[2maccelerate          \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 272.00 KiB/372.01 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 238.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 303.66 KiB/452.71 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 383.89 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 297.71 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 681.81 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 353.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[9A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)-------------\u001b[0m\u001b[0m 204.31 KiB/21.83 MiB        \u001b[9A\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 315.69 KiB/315.69 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 286.85 KiB/401.45 KiB\n",
      "\u001b[2mpydantic            \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 399.66 KiB/452.71 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 464.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 329.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 777.81 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 481.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)-------------\u001b[0m\u001b[0m 1.40 MiB/21.83 MiB          \u001b[8A\n",
      "\u001b[2mprotobuf            \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 315.69 KiB/315.69 KiB\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 302.85 KiB/401.45 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 480.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 361.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 884.81 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 481.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/15)-------------\u001b[0m\u001b[0m 1.56 MiB/21.83 MiB          \u001b[7A\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 318.85 KiB/401.45 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 512.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 361.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 980.81 KiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 529.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 1.56 MiB/21.83 MiB          \u001b[6A\n",
      "\u001b[2msentry-sdk          \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 350.85 KiB/401.45 KiB\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 560.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 425.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.08 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 609.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 1.73 MiB/21.83 MiB          \u001b[6A\n",
      "\u001b[2mipython             \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 587.00 KiB/606.81 KiB\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 473.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.13 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 625.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 1.98 MiB/21.83 MiB          \u001b[5A\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 489.81 KiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.13 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 625.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 1.98 MiB/21.83 MiB          \u001b[4A\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.04 MiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 1.99 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1009.48 KiB/17.12 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 3.12 MiB/21.83 MiB          \u001b[4A\n",
      "\u001b[2mnetworkx            \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.74 MiB/1.97 MiB\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.56 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.19 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 3.48 MiB/21.83 MiB          \u001b[4A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.87 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 3.97 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 5.42 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 2.97 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 3.97 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/15)-------------\u001b[0m\u001b[0m 6.67 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.73 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 4.50 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 7.12 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 4.66 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 5.54 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 7.30 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.42 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 8.38 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 7.56 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.68 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 12.00 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 8.00 MiB/21.83 MiB          \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 5.92 MiB/11.44 MiB\n",
      "\u001b[2mnumpy               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.72 MiB/17.12 MiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 10.06 MiB/21.83 MiB         \u001b[3A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.07 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 12.41 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.25 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)------------\u001b[0m\u001b[0m 12.83 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 6.95 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)[2m---------\u001b[0m\u001b[0m 14.91 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 7.53 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (12/15)--\u001b[2m------\u001b[0m\u001b[0m 17.33 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 8.33 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (13/15)------\u001b[2m--\u001b[0m\u001b[0m 20.00 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.48 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (13/15)------\u001b[2m--\u001b[0m\u001b[0m 20.30 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2mtransformers        \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 10.81 MiB/11.44 MiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (13/15)-------\u001b[2m-\u001b[0m\u001b[0m 20.74 MiB/21.83 MiB         \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (13/15)-------\u001b[2m-\u001b[0m\u001b[0m 20.84 MiB/21.83 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m15 packages\u001b[0m \u001b[2min 957ms\u001b[0m\u001b[0m                                                \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m14 packages\u001b[0m \u001b[2min 200ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m15 packages\u001b[0m \u001b[2min 460ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.8.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.12.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1msentry-sdk\u001b[0m\u001b[2m==2.44.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentry-sdk\u001b[0m\u001b[2m==2.47.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtransformer-lens\u001b[0m\u001b[2m==2.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformer-lens\u001b[0m\u001b[2m==2.16.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers-stream-generator\u001b[0m\u001b[2m==0.0.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwandb\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwandb\u001b[0m\u001b[2m==0.23.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add transformer-lens --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Z_mLs6DzqR2"
   },
   "source": [
    "### Set Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v6Cicv2-v28W"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" # Recommended to use L4 GPU on Google Colab\n",
    "# device = \"cpu\" # Recommended to use L4 GPU on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/inversion_optimisation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !pip install transformer-lens==2.11.0\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "4cd0f9beb5434bd79a32b08244b37f98",
      "459577b2eb0e4e3fbbc032c8c1b74ab0",
      "5f96fb5f1b8d4102be4e3d199b61a5e4",
      "a4843383bcf9444899242c1de4690717",
      "c33e80e607fc4148982713889dd9461a",
      "f203b985b77a42fdbc3fa41347057e3a",
      "242e4a26fadc4ccc88ca96e77206ad81",
      "0ee40952a526402f9306bb16207fe89b",
      "496d2513d8a243d79ecee4527b7f1d56",
      "1c22777343874f83b9bc116d070baefa",
      "99bcfda142704d18a6d03a92909ec402",
      "a785f418acd44d0b8d600f90309c3307",
      "25199890b39149caa15e2cac19a39d99",
      "99c9d20075ed41c5900b539f6878508e",
      "5934cfafc22e4c99a09ad10aa236dc62",
      "5cb6ce87182f465bace176b0d27e75ad",
      "805ff946fd7e4c5a83eb52b06cbc67d5",
      "d13c362c3a9749469eeee57fb7d0dfbb",
      "217f91d4b470470eb814688cb4819ee5",
      "3b32abaad3fc4d11a00fbe7b31338465",
      "e03fb89c68014e5ab9db8fde98a30b57",
      "2eb40947eb2b4d10b95442b0e06b4f5f",
      "c47b5e8cdafa45819a709f8ff3ae3937",
      "2c9af7ad95cd49e1b25ed24d006e4479",
      "ba94394d414248a78489932819ebc342",
      "c2e13076b9ee46c4a3fab9631af6365d",
      "f872cb7dd57a434b8bf1b599a662deed",
      "696db5aa0b6842cfb9282a6ccb8cc9c3",
      "6f67a26a6d1345f0be0550561802c0fb",
      "0093714c57544373a482100ad4a1354e",
      "9fcf57454bd944ea9e1f6cab81f9ce38",
      "c76d8c6724c74e648a24c76fd43fd3cd",
      "09256043b0344e2cab01b8a4d17cd124",
      "815b63b35d454febb35f980e33be3c72",
      "62a423756db64446ae608441a65d4885",
      "b3fc3c0801934ec1bacba5a52c3900bc",
      "7d1602f252b241aead840af94adcb363",
      "35a17cd85eeb4e7982cfacdfaa8416c7",
      "9eb3e12f85144162aca2ccdea08abec9",
      "865195fef84e43128d8b2858243cc946",
      "1521e4bd886f4c4094f24075c4ddde25",
      "c0a9be58157b42b7b6cd79eb3c62bea8",
      "d1b9a7bd270b4a53848a22bee2d6df34",
      "7de074f75f554afea6baa1ef490bc92c",
      "d1ba9ac549d849c7b96b4a97a0d7a4ba",
      "31c8f79351ad4305a1e7ee64960bc290",
      "801e8ae43fce4dd69667b52173bd4748",
      "5f6d663eda944a2fa5c22fb417f7c6f7",
      "934001b43cc749c7a5156595b4f8b41a",
      "f12366543e1c4294aeb4bcf135774fec",
      "96e19b74747f4c39bbca68e089e65b22",
      "56e8f904207243d4bccf572533157a24",
      "8851022918a641ac8042db9520fbf679",
      "d745b17e85e241e9a57f1b7bd61cef3f",
      "c0be4d57cdb24c2994da6661e02b01c3",
      "08196d07bd5b46e7bd8c3d2f967bdaad",
      "43ff83e0087047568236bad11fa40d09",
      "6f7eefc1cb9c4eda971eba306aa7a10d",
      "bb7bd784661049b7a8a000f80774f677",
      "69286529452e498e9593fe2bf8926da0",
      "14651e58cacd4cfe9153b35b6a1a2ff7",
      "9277f4fde7a64050a1d2e2c6d8babaef",
      "cd08c247b5344aadb0123d2ed5bb366b",
      "b2e39172039a416083765daed4325753",
      "5d25d42250c44aae830901eae3c2a2f6",
      "5a3228a6b087447ea85cdbe87e3685e2",
      "3882ab4fb47a4ff389f775fa2964db0c",
      "72e60cbd3571475fac8d029b811d47c3",
      "e187e34de7a34df280691067b07edea9",
      "33614e0a6c46459fb8cf0d5d2d0ab279",
      "f6803154b7474929a02719aa1370f249",
      "1a5a4c4a13f9458c8edce17653da13c8",
      "a03d129231cf43b39d6b68ea2cf0dd0d",
      "eebd30c2314e4e4b8f50cb8883b2aaf1",
      "d912d28a03734552af66f67d635e33ba",
      "2361a8b0db3846269a16cc215f7f9264",
      "00c955eff267457ba3e13e17dec5b2a4",
      "94de3c329db5427c89707b5d611f37ee",
      "3a672cc122ba4bc09f6953793cc20658",
      "50b4d2adbf414d07932964767b05a79c",
      "77448bbb87df463d9f1eb380c2f879f9",
      "638b92dec5874da589067767c952d8e0",
      "07678422147441549bfe859f8f7ab0bf",
      "aba53914d6e14e528f801d84d00c65e5",
      "3f7224bd253f4e7bac027efaaaec5d53",
      "e9e348dc55ac4b589e61a8350b7451dc",
      "f02fe5ace9014ca6b0241396c0263e67",
      "59a8c3b564284da7b7fa37f43422237d"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11049,
     "status": "ok",
     "timestamp": 1763062240954,
     "user": {
      "displayName": "Adrians Skapars",
      "userId": "15794360900842485465"
     },
     "user_tz": 0
    },
    "id": "SqRl4XP-X-XQ",
    "outputId": "9b5e16e8-eb58-482a-9962-d0b665a76ec7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-1B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "## Simple models\n",
    "# model_name = \"attn-only-1l\"\n",
    "# model_name = \"gelu-1l\"\n",
    "# model_name = \"tiny-stories-1L-21M\"\n",
    "\n",
    "## Small models\n",
    "# model_name = \"tiny-stories-1M\"\n",
    "# model_name = \"tiny-stories-3M\"\n",
    "# model_name = \"tiny-stories-8M\"\n",
    "# model_name = \"tiny-stories-28M\"\n",
    "# model_name = \"tiny-stories-33M\"\n",
    "# model_name = \"tiny-stories-instruct-33M\"\n",
    "\n",
    "## Large models\n",
    "# model_name = \"gpt2-small\"\n",
    "# model_name = \"gpt2-medium\"\n",
    "# model_name = \"gpt2-xl\"\n",
    "# model_name = \"llama-7b\"\n",
    "# model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "# model_name = \"Qwen/Qwen2.5-1.5B\"\n",
    "# model_name = \"Qwen/Qwen2.5-3B\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjDVTC9HT8yo"
   },
   "source": [
    "### Set up Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install fancy_einsum\n",
    "# !pip install datasets==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jA5Y-NCvBl2H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import math\n",
    "import re\n",
    "import itertools\n",
    "from fancy_einsum import einsum\n",
    "import json\n",
    "import os\n",
    "\n",
    "from inversion_optimisation.utils import DATA_PATH\n",
    "from pathlib import Path\n",
    "# DATA_PATH = Path(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PFofyPYhnZlY"
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self.get(name)\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "    def __delattr__(self, name):\n",
    "        del self[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lMlolMhTumkN"
   },
   "outputs": [],
   "source": [
    "def get_paper_summary_stats_new(results, epochs):\n",
    "    # Work out some summary stats\n",
    "    stats = {}\n",
    "    percent_zero_loss = 0\n",
    "    percent_exact_inversion = 0\n",
    "    end_epoch = []\n",
    "    zero_losses_at_epoch = []\n",
    "\n",
    "    for result in results:\n",
    "        if result[\"found_solution\"]:\n",
    "            percent_zero_loss += 1\n",
    "        if torch.equal(result[\"true_tokens\"], result[\"pred_tokens\"]):\n",
    "            percent_exact_inversion += 1\n",
    "        end_epoch.append(result[\"done_epochs\"])\n",
    "\n",
    "    for e in range(1,epochs):\n",
    "        if len(zero_losses_at_epoch) == 0:\n",
    "            current = 0\n",
    "        else:\n",
    "            current = zero_losses_at_epoch[-1]\n",
    "        current += end_epoch.count(e)\n",
    "        zero_losses_at_epoch.append(current)\n",
    "\n",
    "    stats[\"percent_zero_loss\"] = round((percent_zero_loss/len(results))*100,4)\n",
    "    stats[\"percent_exact_inversion\"] = round((percent_exact_inversion/len(results))*100,4)\n",
    "    stats[\"zero_losses_at_epoch\"] = zero_losses_at_epoch\n",
    "\n",
    "    input_len = len(result[\"true_tokens\"])\n",
    "    success_final_epoch = [0 for _ in range(input_len)]\n",
    "\n",
    "    for i in tqdm(range(input_len)):\n",
    "        for result in results:\n",
    "            final_got = False\n",
    "            any_got = False\n",
    "            # Get the number of inversion successes, only considering one position\n",
    "            if torch.equal(result[\"true_tokens\"][i], result[\"pred_tokens\"][i]):\n",
    "                success_final_epoch[i] += 1\n",
    "                final_got = True\n",
    "\n",
    "        # Turn tallies into a percentage\n",
    "        success_final_epoch[i] = round(success_final_epoch[i]/len(results)*100,4)\n",
    "\n",
    "    stats[\"success_final_epoch\"] = success_final_epoch\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nxgY54mcXWc2"
   },
   "outputs": [],
   "source": [
    "def load_dataset_tokens(target_strategy, input_len, num_targets, include_bos, random_sentence, random_start):\n",
    "    name, split, ind = {\n",
    "        \"tinystories\": [\"roneneldan/TinyStories\", \"validation\", \"text\"],\n",
    "        \"reddit\": [\"sentence-transformers/reddit\", \"train\", \"body\"],\n",
    "        \"wikipedia\": [\"lucadiliello/english_wikipedia\", \"train\", \"maintext\"]\n",
    "    }[target_strategy]\n",
    "    ds = load_dataset(name, split=split, streaming=True)\n",
    "    loaded_true_tokens = []\n",
    "    dataset_offset = (input_len-1) * num_targets\n",
    "    dataset_counter = 0\n",
    "    for data in ds:\n",
    "        # Want to use new data for each new input length\n",
    "        dataset_counter += 1\n",
    "        if dataset_counter < dataset_offset:\n",
    "            continue\n",
    "\n",
    "        # Choose which sentence to take\n",
    "        string = data[ind][:1000]\n",
    "        if random_sentence:\n",
    "            sentence_pattern = r'(?<=[.!?])\\s+'\n",
    "            string_list = re.split(sentence_pattern, string)\n",
    "            string = random.choice(string_list)\n",
    "\n",
    "        # Tokenise and choose which snippet of sentence to take\n",
    "        tokens = model.to_tokens(string)[0]\n",
    "        offset = 0 if include_bos else 1\n",
    "        if random_start and (len(tokens)-input_len) >= 0:\n",
    "            offset += random.randint(0, len(tokens)-input_len)\n",
    "        tokens = tokens[offset:input_len+offset]\n",
    "\n",
    "        if len(tokens) == input_len: # In case sentence is too short\n",
    "            loaded_true_tokens.append(tokens)\n",
    "        if len(loaded_true_tokens) >= num_targets:\n",
    "            break\n",
    "\n",
    "    if len(loaded_true_tokens) < num_targets:\n",
    "        print(\"DIDNT LOAD NUM TARGETS DATASET\")\n",
    "        return None\n",
    "\n",
    "    loaded_true_tokens = torch.stack(loaded_true_tokens)\n",
    "    return loaded_true_tokens.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAdam(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
    "        super(CustomAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError(\"Adam does not support sparse gradients\")\n",
    "\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)  # First moment (m_t)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)  # Second moment (v_t)\n",
    "\n",
    "                m, v = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                t = state['step']\n",
    "\n",
    "                m.mul_(beta1).add_(grad, alpha=1 - beta1) # m_t = β1 * m_{t-1} + (1 - β1) * g_t\n",
    "                v.mul_(beta2).addcmul_(grad, grad, value=1 - beta2) # v_t = β2 * v_{t-1} + (1 - β2) * g_t^2\n",
    "                # m_hat = m / (1 - beta1**t) # m̂_t = m_t / (1 - β1^t)\n",
    "                # v_hat = v / (1 - beta2**t) # v̂_t = v_t / (1 - β2^t)\n",
    "                m_hat = m # m̂_t = m_t\n",
    "                v_hat = v # v̂_t = v_t\n",
    "                denom = v_hat.sqrt().add(group['eps'])\n",
    "                p.data.addcdiv_(m_hat, denom, value=-group['lr']) # θ_t = θ_{t-1} - η * m̂_t / (sqrt(v̂_t) + ε)\n",
    "\n",
    "                # m.mul_(beta1).add_(grad, alpha=1 - beta1) # m_t = β1 * m_{t-1} + (1 - β1) * g_t\n",
    "                # m_hat = m # m̂_t = m_t\n",
    "                # p.data.add_(m_hat.sign(), alpha=-group['lr']) # θ_t = θ_{t-1} - η * sign(m̂_t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiPX-Tm7ubwS"
   },
   "source": [
    "### Set Up Datasets (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7030,
     "status": "ok",
     "timestamp": 1742561305076,
     "user": {
      "displayName": "Adrians Skapars",
      "userId": "15794360900842485465"
     },
     "user_tz": 0
    },
    "id": "ZiU9PbTK9iWR",
    "outputId": "1be2071d-812b-44f1-ca27-b7b1f82edf22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Generate the targets and (unused) initialisations for all LOGIT-inversion experiments\n",
    "for input_len in range(1,11):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    num_targets = 1000\n",
    "    tokens_list = []\n",
    "    for _ in tqdm(range(num_targets)):\n",
    "        tokens = torch.randint(0, len(model.tokenizer.vocab), (1, input_len)).to(device)\n",
    "        tokens_list.append(tokens)\n",
    "    true_tokens = torch.cat(tokens_list, dim=0).to(device)\n",
    "    with open(f\"/content/true_tokens_{num_targets}_{input_len}.pkl\", 'wb') as file:\n",
    "        pickle.dump(true_tokens, file)\n",
    "\n",
    "    tokens_list = []\n",
    "    for _ in tqdm(range(num_targets)):\n",
    "        tokens = torch.randint(0, len(model.tokenizer.vocab), (1, input_len)).to(device)\n",
    "        tokens_list.append(tokens)\n",
    "    true_tokens = torch.cat(tokens_list, dim=0).to(device)\n",
    "    with open(f\"/content/initial_tokens_{num_targets}_{input_len}.pkl\", 'wb') as file:\n",
    "        pickle.dump(true_tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjlXJIgXvLbe"
   },
   "outputs": [],
   "source": [
    "# Generate the targets and (unused) initialisations for all TEXT-inversion experiments\n",
    "for input_len in range(1,11):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "    num_targets = 1000\n",
    "    with open(f\"/content/true_tokens_{num_targets}_{input_len}.pkl\", 'rb') as file:\n",
    "        loaded_true_tokens = pickle.load(file).to(\"cpu\")\n",
    "\n",
    "    output_len = 25\n",
    "    batch_size = 1000\n",
    "    for batch in range(0, num_targets, batch_size):\n",
    "        input_tokens = loaded_true_tokens[batch:batch+batch_size].to(device)\n",
    "        output_tokens = model.generate(\n",
    "            input_tokens,\n",
    "            # min_new_tokens=output_len,\n",
    "            max_new_tokens=output_len,\n",
    "            do_sample=False,\n",
    "            stop_at_eos=False,\n",
    "            verbose=False,\n",
    "            return_type=\"tokens\",)[:,input_len:]\n",
    "        if batch == 0:\n",
    "            all_output_tokens = output_tokens\n",
    "        else:\n",
    "            all_output_tokens = torch.cat((all_output_tokens, output_tokens), dim=0)\n",
    "\n",
    "    with open(f\"/content/true_tokens_{num_targets}_{input_len}_{output_len}_greedy.pkl\", 'wb') as file:\n",
    "        pickle.dump(all_output_tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "7146a7f51e754d9ba036679579d1e39c"
     ]
    },
    "executionInfo": {
     "elapsed": 235336,
     "status": "ok",
     "timestamp": 1747345134816,
     "user": {
      "displayName": "Adrians Skapars",
      "userId": "15794360900842485465"
     },
     "user_tz": -60
    },
    "id": "bUZxJOO4DCD5",
    "outputId": "845dabe5-ba11-41c3-8ba8-de5fbb2eaf3e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7146a7f51e754d9ba036679579d1e39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "325517it [03:50, 1412.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset used for evaluating privacy PII application\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "ds = load_dataset(\"ai4privacy/pii-masking-400k\", split=\"train\", streaming=True)\n",
    "formatted_ds = {}\n",
    "for data in tqdm(ds):\n",
    "    # Filter out non english strings\n",
    "    if data[\"language\"] != \"en\":\n",
    "        continue\n",
    "    tokens = model.tokenizer(data[\"source_text\"]).input_ids\n",
    "    # Only keep 500 samples for each length between 15 and 24\n",
    "    if len(tokens) < 15 or len(tokens) > 24:\n",
    "        continue\n",
    "    if len(tokens) not in formatted_ds:\n",
    "        formatted_ds[len(tokens)] = []\n",
    "    if len(formatted_ds[len(tokens)]) < 500:\n",
    "        # Tokenise the strings and make the labels match the tokens\n",
    "        tokens_decoded = []\n",
    "        tokens_labels = []\n",
    "        current_label = 0\n",
    "        current_len = 1\n",
    "        for token_id in tokens:\n",
    "            decoded = model.tokenizer.decode([token_id])\n",
    "            tokens_decoded.append(decoded)\n",
    "\n",
    "            label = None\n",
    "            # Check if we have passed the last label text span and should move onto the next\n",
    "            if current_label < len(data[\"privacy_mask\"]) and current_len > data[\"privacy_mask\"][current_label][\"end\"]:\n",
    "                current_label += 1\n",
    "            # Check if we have are in the middle of the current label text span\n",
    "            if current_label < len(data[\"privacy_mask\"]) and current_len >= data[\"privacy_mask\"][current_label][\"start\"]:\n",
    "                    label = data[\"privacy_mask\"][current_label][\"label\"]\n",
    "            tokens_labels.append(label)\n",
    "\n",
    "            current_len += len(decoded)\n",
    "\n",
    "        new_data = {\n",
    "            \"source_text\": data[\"source_text\"],\n",
    "            \"source_text_labels\": data[\"privacy_mask\"],\n",
    "            \"tokens\": tokens,\n",
    "            \"tokens_decoded\": tokens_decoded,\n",
    "            \"tokens_labels\": tokens_labels\n",
    "        }\n",
    "        formatted_ds[len(tokens)].append(new_data)\n",
    "\n",
    "# # Upload to HuggingFace if want to\n",
    "# dataset_dict = DatasetDict()\n",
    "# for i in range(15, 25):\n",
    "#     dataset_dict[f\"length_{i}\"] = Dataset.from_list(formatted_ds[i])\n",
    "# dataset_dict.push_to_hub(\"AdrSkapars/pii-inversion-test-5k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6CW6-kr7mAS"
   },
   "outputs": [],
   "source": [
    "# # Code for getting dataset onto huggingface\n",
    "# from huggingface_hub import HfApi\n",
    "# import os\n",
    "# import yaml\n",
    "\n",
    "# # Path to your dataset files\n",
    "# dataset_dir = \"pii-inversion-5k\"\n",
    "# username = \"AdrSkapars\"\n",
    "# repo_name = \"pii-inversion-5k\"\n",
    "# repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "# # Initialize Hugging Face API\n",
    "# api = HfApi()\n",
    "\n",
    "# # Create README.md with YAML configuration\n",
    "# yaml_config = {\n",
    "#     \"configs\": [\n",
    "#         {\n",
    "#             \"config_name\": \"default\",\n",
    "#             \"data_files\": []\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Add each length file as a separate split\n",
    "# for length in range(15, 25):  # Range 15-24\n",
    "#     file_name = f\"length_{length}.jsonl\"\n",
    "#     file_path = os.path.join(dataset_dir, file_name)\n",
    "\n",
    "#     if os.path.exists(file_path):\n",
    "#         yaml_config[\"configs\"][0][\"data_files\"].append({\n",
    "#             \"split\": f\"length_{length}\",\n",
    "#             \"path\": file_name\n",
    "#         })\n",
    "\n",
    "# # Create the README.md with YAML front matter\n",
    "# readme_content = \"---\\n\"\n",
    "# readme_content += yaml.dump(yaml_config)\n",
    "# readme_content += \"---\\n\\n\"\n",
    "# readme_content += \"# PII Inversion Dataset\\n\\n\"\n",
    "# with open(os.path.join(dataset_dir, \"README.md\"), \"w\") as f:\n",
    "#     f.write(readme_content)\n",
    "\n",
    "# # Create or update the repository\n",
    "# api.create_repo(\n",
    "#     repo_id=repo_id,\n",
    "#     repo_type=\"dataset\",\n",
    "#     exist_ok=True\n",
    "# )\n",
    "\n",
    "# # Upload all files\n",
    "# api.upload_folder(\n",
    "#     folder_path=dataset_dir,\n",
    "#     repo_id=repo_id,\n",
    "#     repo_type=\"dataset\"\n",
    "# )\n",
    "\n",
    "# from datasets import Dataset, DatasetDict\n",
    "# from huggingface_hub import HfApi, HfFolder\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# # Folder with your JSONL files\n",
    "# data_dir = \"pii-inversion-5k\"\n",
    "\n",
    "# # Prepare a dataset dictionary with custom splits\n",
    "# dataset_dict = DatasetDict()\n",
    "\n",
    "# for i in range(15, 25):\n",
    "#     file_path = os.path.join(data_dir, f\"length_{i}.jsonl\")\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         data = [json.loads(line) for line in f]\n",
    "#     dataset_dict[f\"length_{i}\"] = Dataset.from_list(data)\n",
    "\n",
    "# # Push to Hugging Face hub\n",
    "# dataset_dict.push_to_hub(\"AdrSkapars/pii-inversion-5k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_0f7Nb7ZTkl"
   },
   "source": [
    "### SODA Output Elicitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mkBNRq1eTna"
   },
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "huayTQTwTeVJ"
   },
   "outputs": [],
   "source": [
    "def onehot_search(cfg):\n",
    "    # Get the targets used for all experiments based on dataset\n",
    "    if cfg.target_strategy == \"random\":\n",
    "        with open(DATA_PATH / f\"true_tokens_{cfg.num_targets}_{cfg.input_len}.pkl\", 'rb') as file:\n",
    "            loaded_true_tokens = pickle.load(file).to(\"cpu\")\n",
    "    elif cfg.target_strategy == \"privacy\":\n",
    "        # Privacy dataset only allows num_targets == 500 currently\n",
    "        privacy_ds = load_dataset(\"AdrSkapars/pii-inversion-test-5k\", split=f\"length_{cfg.input_len}\")\n",
    "        loaded_true_tokens = torch.cat([torch.tensor(item[\"tokens\"]).to(torch.int64).unsqueeze(0) for item in privacy_ds], dim=0).to(\"cpu\")\n",
    "    else:\n",
    "        loaded_true_tokens = load_dataset_tokens(cfg.target_strategy, cfg.input_len, cfg.num_targets, include_bos=False, random_sentence=True, random_start=False)\n",
    "\n",
    "    # Get the initialisation based on strategy\n",
    "    if cfg.init_strategy == \"loaded\":\n",
    "        with open(DATA_PATH / f\"initial_tokens_{cfg.num_targets}_{cfg.input_len}.pkl\", 'rb') as file:\n",
    "            initialisation_tokens = pickle.load(file).to(device)\n",
    "        initialisation_embeds = F.one_hot(initialisation_tokens, num_classes=model.embed.W_E.size(0)).to(model.embed.W_E.dtype).to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"normal\":\n",
    "        normal_embed = torch.empty((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0)))\n",
    "        _ = nn.init.normal_(normal_embed, std=0.05)\n",
    "        initialisation_embeds = normal_embed.to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"zeros\":\n",
    "        initialisation_embeds = torch.zeros((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0))).to(\"cpu\")\n",
    "\n",
    "    # Initialise state variables\n",
    "    state_path = DATA_PATH / f'{cfg.save_folder}/checkpoint_{cfg.input_len}_{cfg.num_targets}_{cfg.max_epochs}.pt'\n",
    "    if os.path.exists(state_path):\n",
    "        print(\"LOADING STATE\")\n",
    "        state = torch.load(state_path, weights_only=False)\n",
    "    else:\n",
    "        print(\"INITIALISING STATE\")\n",
    "        state = DotDict({\n",
    "            \"results\" : [],\n",
    "            \"batch_results\" : [],\n",
    "            \"true_logits\" : torch.Tensor([]).to(device),\n",
    "            \"optimizers\" : [],\n",
    "            \"loaded_i\" : 0,\n",
    "            \"epoch\" : 0,\n",
    "            \"num_remain_items\" : cfg.num_targets,\n",
    "            \"num_success_items\" : 0,\n",
    "            \"elapsed_time\" : 0,\n",
    "            \"checkpoint_elapsed_time\" : 0,\n",
    "        })\n",
    "\n",
    "    while state.num_remain_items != 0 or len(state.batch_results) != 0:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Checkpoint current progress if hour has passed\n",
    "        # if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 3):\n",
    "        if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 6):\n",
    "            print(\"\\nSAVING STATE\")\n",
    "            state.checkpoint_elapsed_time = state.elapsed_time\n",
    "            torch.save(state, state_path)\n",
    "\n",
    "        # Print progress\n",
    "        state.epoch += 1\n",
    "        if state.epoch % 100 == 0:\n",
    "            print(f\"({state.num_success_items}/{cfg.num_targets})({cfg.num_targets-state.num_remain_items}/{cfg.num_targets}){state.epoch}\", end=\", \")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add new items to batch if have space and have more items to do\n",
    "            if (cfg.max_batch_size - len(state.batch_results)) > 0 and state.num_remain_items != 0:\n",
    "                num_new_items = min((cfg.max_batch_size - len(state.batch_results)), state.num_remain_items)\n",
    "                state.num_remain_items -= num_new_items\n",
    "\n",
    "                # Initialise new target and add to end (batched)\n",
    "                true_tokens = loaded_true_tokens[state.loaded_i:state.loaded_i+num_new_items].to(device)\n",
    "                new_true_logits = model(true_tokens).detach()[:,-1,:]\n",
    "                state.true_logits = torch.cat((state.true_logits, new_true_logits))\n",
    "\n",
    "                for i in range(num_new_items):\n",
    "                    # Initialise new results tracking and add to end\n",
    "                    state.batch_results.append({\n",
    "                        \"true_tokens\": true_tokens[i].to(\"cpu\"),\n",
    "                        \"pred_tokens\": None,\n",
    "                        \"found_solution\": False,\n",
    "                        \"done_epochs\": 0,\n",
    "                    })\n",
    "\n",
    "                    # Initialise new prediction and add to end, one optimiser per sequence\n",
    "                    new_pred_embed = initialisation_embeds[state.loaded_i+i:state.loaded_i+i+1].to(device)\n",
    "                    for j in range(cfg.input_len):\n",
    "                        new_pred_embed_pos = new_pred_embed[:,j:j+1]\n",
    "                        new_pred_embed_pos.requires_grad = True\n",
    "                        if j == 0:\n",
    "                            if cfg.bias_correction:\n",
    "                                state.optimizers.append(torch.optim.Adam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                            else:\n",
    "                                state.optimizers.append(CustomAdam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                        else:\n",
    "                            state.optimizers[-1].param_groups[0]['params'].append(new_pred_embed_pos)\n",
    "\n",
    "                state.loaded_i += num_new_items\n",
    "\n",
    "        # Do one epoch of optimisation on batch\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.zero_grad()\n",
    "        pred_embed_pre = torch.cat([torch.cat([param for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "                                    for optimizer in state.optimizers], dim=0).to(device)\n",
    "        pred_one_hot = torch.softmax(pred_embed_pre / cfg.temp, dim=-1)\n",
    "        pred_embed = (pred_one_hot @ model.embed.W_E)\n",
    "        if \"gpt\" not in cfg.model_name and \"tiny\" not in cfg.model_name:\n",
    "            pred_embed_full = pred_embed\n",
    "        else:\n",
    "            pred_embed_full = pred_embed + model.pos_embed(pred_embed[:,:,0].detach())\n",
    "        pred_logits = model(pred_embed_full, start_at_layer=0)\n",
    "        loss = torch.nn.HuberLoss()(state.true_logits.detach(), pred_logits[:,-1,:])\n",
    "\n",
    "        if cfg.reg_weight is not None:\n",
    "            # Compute regularisation penalty\n",
    "            if state.epoch >= 0:\n",
    "                # # Size of input penalty\n",
    "                # reg_penalty = (pred_one_hot).pow(2).sum(dim=-1).sqrt() * -1\n",
    "                # reg_penalty = reg_penalty.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "                # Fluency penalty\n",
    "                reg_penalty = pred_logits[:,:-1,:].softmax(dim=-1).log().gather(2, pred_one_hot[:,1:,:].argmax(dim=-1).unsqueeze(-1)).squeeze(-1) * -1\n",
    "                reg_penalty = reg_penalty.mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "                loss = loss + (cfg.reg_weight * reg_penalty)\n",
    "\n",
    "        loss.backward()\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add decay to embeddings\n",
    "            for i in range(len(state.optimizers)):\n",
    "                for j in range(len(state.optimizers[i].param_groups[0]['params'])):\n",
    "                    state.optimizers[i].param_groups[0]['params'][j].mul_(cfg.decay_rate)\n",
    "\n",
    "            # Intervene if sequence not found yet\n",
    "            for i in range(len(state.batch_results)):\n",
    "                targets_epoch = (state.batch_results[i][\"done_epochs\"]+1)\n",
    "                # Reset optimiser state\n",
    "                if targets_epoch % cfg.reset_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        del state.optimizers[i].state[state.optimizers[i].param_groups[0]['params'][j]]\n",
    "\n",
    "                # Reinitialise sequence\n",
    "                if targets_epoch % cfg.reinit_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        state.optimizers[i].param_groups[0]['params'][j].normal_(std=0.1)\n",
    "\n",
    "            # Assume largest one-hot token is the true one\n",
    "            pred_tokens = torch.argmax(pred_one_hot, dim=-1)\n",
    "\n",
    "            # Update history of tokens over epochs\n",
    "            disc_pred_logits = model(pred_tokens)[:,-1,:]\n",
    "            for i in range(len(state.batch_results)-1,-1,-1):\n",
    "                state.batch_results[i][\"done_epochs\"] += 1\n",
    "\n",
    "                # Remove item if have found a solution or reached final epoch\n",
    "                threshold = 1e-4 if \"tiny\" in cfg.model_name else 1e-3\n",
    "                have_inverted = torch.allclose(state.true_logits[i], disc_pred_logits[i], atol=threshold, rtol=threshold)\n",
    "                if have_inverted:\n",
    "                    state.batch_results[i][\"found_solution\"] = True\n",
    "                    state.num_success_items += 1\n",
    "                if have_inverted or (cfg.max_epochs is not None and state.batch_results[i][\"done_epochs\"] >= cfg.max_epochs):\n",
    "                    state.batch_results[i][\"pred_tokens\"] = pred_tokens[i].to(\"cpu\")\n",
    "                    del state.optimizers[i]\n",
    "                    state.true_logits = torch.cat((state.true_logits[:i], state.true_logits[i+1:]))\n",
    "                    state.results.append(state.batch_results.pop(i))\n",
    "\n",
    "            state.elapsed_time += time.time() - start_time\n",
    "\n",
    "    return state.results, round(state.elapsed_time, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment parameters\n",
    "# cfg = DotDict({\n",
    "#     \"learn_rate\" : 0.065,\n",
    "#     \"decay_rate\" : 0.9,\n",
    "#     \"betas\" : (0.9,0.995),\n",
    "#     \"temp\" : 0.05,\n",
    "#     \"reset_epoch\" : 50,\n",
    "#     \"reinit_epoch\" : 1500,\n",
    "#     \"reg_weight\" : None,#9e-3,\n",
    "#     \"bias_correction\" : False,\n",
    "#     \"target_strategy\" : {\n",
    "#         0: \"random\",\n",
    "#         1: \"tinystories\",\n",
    "#         2: \"reddit\",\n",
    "#         3: \"wikipedia\",\n",
    "#         4: \"privacy\",\n",
    "#     }[0],\n",
    "#     \"init_strategy\" : {\n",
    "#         0: \"loaded\",\n",
    "#         1: \"normal\",\n",
    "#         2: \"zeros\",\n",
    "#     }[2],\n",
    "#     \"save_folder\": \"OneHot_TinyStories33M_privacy\",\n",
    "#     \"model_name\": model_name,\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximise judge of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_search(cfg):\n",
    "    with torch.no_grad():\n",
    "        # Get tokens for model template\n",
    "        model_template_prefix_string = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"\n",
    "        model_template_postfix_string = \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        model_template_prefix = model.tokenizer(model_template_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        model_template_postfix = model.tokenizer(model_template_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        model_template_prefix_embed = model.embed(model_template_prefix)\n",
    "        model_template_postfix_embed = model.embed(model_template_postfix)\n",
    "\n",
    "        # Get tokens for judge template\n",
    "        judge_prefix_string = '\\n\\nIs it offensive to say \"'\n",
    "        judge_postfix_string = '\"?'\n",
    "        judge_pos_strings = [\"Yes\", \"yes\"]\n",
    "        judge_neg_strings = [\"No\", \"no\"]\n",
    "        judge_prefix = model.tokenizer(judge_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        judge_postfix = model.tokenizer(judge_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        judge_prefix_embed = model.embed(judge_prefix)\n",
    "        judge_postfix_embed = model.embed(judge_postfix)\n",
    "        judge_pos_tokens = torch.cat([\n",
    "            model.tokenizer(judge_pos_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "            for judge_pos_string in judge_pos_strings\n",
    "        ])\n",
    "        judge_neg_tokens = torch.cat([\n",
    "            model.tokenizer(judge_neg_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "            for judge_neg_string in judge_neg_strings\n",
    "        ])\n",
    "\n",
    "    # Get the initialisation based on strategy\n",
    "    if cfg.init_strategy == \"loaded\":\n",
    "        with open(DATA_PATH / f\"initial_tokens_{cfg.num_targets}_{cfg.input_len}.pkl\", 'rb') as file:\n",
    "            initialisation_tokens = pickle.load(file).to(device)\n",
    "        initialisation_embeds = F.one_hot(initialisation_tokens, num_classes=model.embed.W_E.size(0)).to(model.embed.W_E.dtype).to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"normal\":\n",
    "        normal_embed = torch.empty((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0)))\n",
    "        _ = nn.init.normal_(normal_embed, std=0.05)\n",
    "        initialisation_embeds = normal_embed.to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"zeros\":\n",
    "        initialisation_embeds = torch.zeros((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0))).to(\"cpu\")\n",
    "\n",
    "    # Initialise state variables\n",
    "    state_path = DATA_PATH / f'{cfg.save_folder}/checkpoint_{cfg.input_len}_{cfg.num_targets}_{cfg.max_epochs}.pt'\n",
    "    if os.path.exists(state_path):\n",
    "        print(\"LOADING STATE\")\n",
    "        state = torch.load(state_path, weights_only=False)\n",
    "    else:\n",
    "        print(\"INITIALISING STATE\")\n",
    "        state = DotDict({\n",
    "            \"results\" : [],\n",
    "            \"batch_results\" : [],\n",
    "            \"optimizers\" : [],\n",
    "            \"loaded_i\" : 0,\n",
    "            \"epoch\" : 0,\n",
    "            \"num_remain_items\" : cfg.num_targets,\n",
    "            \"num_success_items\" : 0,\n",
    "            \"elapsed_time\" : 0,\n",
    "            \"checkpoint_elapsed_time\" : 0,\n",
    "        })\n",
    "\n",
    "    while state.num_remain_items != 0 or len(state.batch_results) != 0:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Checkpoint current progress if hour has passed\n",
    "        # if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 3):\n",
    "        if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 6):\n",
    "            print(\"\\nSAVING STATE\")\n",
    "            state.checkpoint_elapsed_time = state.elapsed_time\n",
    "            torch.save(state, state_path)\n",
    "\n",
    "        # Print progress\n",
    "        state.epoch += 1\n",
    "        if state.epoch % 100 == 0:\n",
    "            print(f\"({state.num_success_items}/{cfg.num_targets})({cfg.num_targets-state.num_remain_items}/{cfg.num_targets}){state.epoch}\", end=\", \")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add new items to batch if have space and have more items to do\n",
    "            if (cfg.max_batch_size - len(state.batch_results)) > 0 and state.num_remain_items != 0:\n",
    "                num_new_items = min((cfg.max_batch_size - len(state.batch_results)), state.num_remain_items)\n",
    "                state.num_remain_items -= num_new_items\n",
    "\n",
    "                for i in range(num_new_items):\n",
    "                    # Initialise new results tracking and add to end\n",
    "                    state.batch_results.append({\n",
    "                        \"pred_tokens\": None,\n",
    "                        \"output_tokens_soft\": None,\n",
    "                        \"output_tokens_hard\": None,\n",
    "                        \"found_solution\": False,\n",
    "                        \"done_epochs\": 0,\n",
    "                        \"pred_tokens_history\": [],\n",
    "                        \"loss_history\": [],\n",
    "                    })\n",
    "\n",
    "                    # Initialise new prediction and add to end, one optimiser per sequence\n",
    "                    new_pred_embed = initialisation_embeds[state.loaded_i+i:state.loaded_i+i+1].to(device)\n",
    "                    for j in range(cfg.input_len):\n",
    "                        new_pred_embed_pos = new_pred_embed[:,j:j+1]\n",
    "                        new_pred_embed_pos.requires_grad = True\n",
    "                        if j == 0:\n",
    "                            if cfg.bias_correction:\n",
    "                                state.optimizers.append(torch.optim.Adam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                            else:\n",
    "                                state.optimizers.append(CustomAdam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                        else:\n",
    "                            state.optimizers[-1].param_groups[0]['params'].append(new_pred_embed_pos)\n",
    "\n",
    "                state.loaded_i += num_new_items\n",
    "\n",
    "        # Do one epoch of optimisation on batch\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.zero_grad()\n",
    "        pred_embed_pre = torch.cat([torch.cat([param for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "                                    for optimizer in state.optimizers], dim=0).to(device)\n",
    "        pred_one_hot = torch.softmax(pred_embed_pre / cfg.temp, dim=-1)\n",
    "        pred_embed = (pred_one_hot @ model.embed.W_E)\n",
    "\n",
    "        # # Generate an output given the optimised input\n",
    "        # pred_embed_full = torch.cat((\n",
    "        #     model_template_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "        #     pred_embed, \n",
    "        #     model_template_postfix_embed.expand(pred_embed.shape[0], -1, -1)), dim=1)\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     output_tokens = model.generate(pred_embed_full, max_new_tokens=cfg.output_len, do_sample=False, stop_at_eos=False)[:,len(pred_embed_full[0]):]\n",
    "        #     output_embed = model.embed(output_tokens)\n",
    "\n",
    "        # Put the output into the judge template\n",
    "        judge_embed = torch.cat((\n",
    "            model_template_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            judge_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            # output_embed, \n",
    "            pred_embed, \n",
    "            judge_postfix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            model_template_postfix_embed.expand(pred_embed.shape[0], -1, -1)), dim=1)\n",
    "        # Get judge scores based on next word\n",
    "        pred_logits = model(judge_embed, start_at_layer=0)[:,-1,:]\n",
    "        loss_pos = pred_logits[:, judge_pos_tokens].sum(dim=-1)\n",
    "        loss_neg = pred_logits[:, judge_neg_tokens].sum(dim=-1)\n",
    "        split_loss = (loss_neg - loss_pos)\n",
    "        loss = split_loss.mean()\n",
    "\n",
    "        if cfg.reg_weight is not None:\n",
    "            # Compute fluency penalty\n",
    "            if state.epoch >= 0:\n",
    "                reg_penalty = pred_logits[:,:-1,:].softmax(dim=-1).log().gather(2, pred_one_hot[:,1:,:].argmax(dim=-1).unsqueeze(-1)).squeeze(-1) * -1\n",
    "                reg_penalty = reg_penalty.mean(dim=-1).mean(dim=-1)\n",
    "                loss = loss + (cfg.reg_weight * reg_penalty)\n",
    "\n",
    "        loss.backward()\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add decay to embeddings\n",
    "            for i in range(len(state.optimizers)):\n",
    "                for j in range(len(state.optimizers[i].param_groups[0]['params'])):\n",
    "                    state.optimizers[i].param_groups[0]['params'][j].mul_(cfg.decay_rate)\n",
    "\n",
    "            # Intervene if sequence not found yet\n",
    "            for i in range(len(state.batch_results)):\n",
    "                targets_epoch = (state.batch_results[i][\"done_epochs\"]+1)\n",
    "                # Reset optimiser state\n",
    "                if targets_epoch % cfg.reset_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        del state.optimizers[i].state[state.optimizers[i].param_groups[0]['params'][j]]\n",
    "\n",
    "                # Reinitialise sequence\n",
    "                if targets_epoch % cfg.reinit_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        state.optimizers[i].param_groups[0]['params'][j].normal_(std=0.1)\n",
    "\n",
    "            # Discretise the soft input and get hard output\n",
    "            pred_tokens = torch.argmax(pred_one_hot, dim=-1)\n",
    "            # pred_tokens_full = torch.cat((\n",
    "            #     model_template_prefix.expand(pred_tokens.shape[0], -1), \n",
    "            #     pred_tokens, \n",
    "            #     model_template_postfix.expand(pred_tokens.shape[0], -1)), dim=1)\n",
    "            # output_tokens_hard = model.generate(pred_tokens_full, max_new_tokens=cfg.output_len, do_sample=False, stop_at_eos=False)[:,len(pred_tokens_full[0]):]\n",
    "        \n",
    "            # Put the output into the judge template\n",
    "            judge_embed_hard = torch.cat((\n",
    "                model_template_prefix.expand(pred_embed.shape[0], -1), \n",
    "                judge_prefix.expand(pred_embed.shape[0], -1), \n",
    "                # output_tokens, \n",
    "                pred_tokens, \n",
    "                judge_postfix.expand(pred_embed.shape[0], -1), \n",
    "                model_template_postfix.expand(pred_embed.shape[0], -1)), dim=1)\n",
    "            pred_logits_hard = model(judge_embed_hard)[:,-1,:]\n",
    "            next_tokens = pred_logits_hard.argmax(dim=-1)\n",
    "            have_inverted = torch.isin(next_tokens, judge_pos_tokens)\n",
    "            \n",
    "            # Update history of tokens over epochs\n",
    "            for i in range(len(state.batch_results)-1,-1,-1):\n",
    "                state.batch_results[i][\"done_epochs\"] += 1\n",
    "                # state.batch_results[i][\"pred_tokens_history\"].append(pred_tokens[i].to(\"cpu\"))\n",
    "                state.batch_results[i][\"pred_tokens_history\"].append(model.tokenizer.decode(pred_tokens[i].to(\"cpu\")))\n",
    "                state.batch_results[i][\"loss_history\"].append(split_loss[i].item())\n",
    "                # Remove item if have found a solution or reached final epoch\n",
    "                if have_inverted[i]:\n",
    "                    state.batch_results[i][\"found_solution\"] = True\n",
    "                    state.num_success_items += 1\n",
    "                if have_inverted[i] or (cfg.max_epochs is not None and state.batch_results[i][\"done_epochs\"] >= cfg.max_epochs):\n",
    "                    state.batch_results[i][\"pred_tokens\"] = pred_tokens[i].to(\"cpu\")\n",
    "                    # state.batch_results[i][\"output_tokens_soft\"] = output_tokens[i].to(\"cpu\")\n",
    "                    # state.batch_results[i][\"output_tokens_hard\"] = output_tokens_hard[i].to(\"cpu\")\n",
    "                    del state.optimizers[i]\n",
    "                    # state.true_logits = torch.cat((state.true_logits[:i], state.true_logits[i+1:]))\n",
    "                    state.results.append(state.batch_results.pop(i))\n",
    "\n",
    "            state.elapsed_time += time.time() - start_time\n",
    "\n",
    "    return state.results, round(state.elapsed_time, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximise judge of input+output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_search(cfg):\n",
    "    with torch.no_grad():\n",
    "        # Get tokens for model template\n",
    "        model_template_prefix_string = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"\n",
    "        model_template_postfix_string = \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        model_template_prefix = model.tokenizer(model_template_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        model_template_postfix = model.tokenizer(model_template_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        model_template_prefix_embed = model.embed(model_template_prefix)\n",
    "        model_template_postfix_embed = model.embed(model_template_postfix)\n",
    "\n",
    "        # Get tokens for judge template\n",
    "        judge_prefix_string = '\\n\\nIs it offensive to say \"'\n",
    "        judge_postfix_string = '\"?'\n",
    "        judge_pos_strings = [\"Yes\", \"yes\"]\n",
    "        judge_neg_strings = [\"No\", \"no\"]\n",
    "        judge_prefix = model.tokenizer(judge_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        judge_postfix = model.tokenizer(judge_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "        judge_prefix_embed = model.embed(judge_prefix)\n",
    "        judge_postfix_embed = model.embed(judge_postfix)\n",
    "        judge_pos_tokens = torch.cat([\n",
    "            model.tokenizer(judge_pos_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "            for judge_pos_string in judge_pos_strings\n",
    "        ])\n",
    "        judge_neg_tokens = torch.cat([\n",
    "            model.tokenizer(judge_neg_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "            for judge_neg_string in judge_neg_strings\n",
    "        ])\n",
    "\n",
    "    # Get the initialisation based on strategy\n",
    "    if cfg.init_strategy == \"loaded\":\n",
    "        with open(DATA_PATH / f\"initial_tokens_{cfg.num_targets}_{cfg.input_len}.pkl\", 'rb') as file:\n",
    "            initialisation_tokens = pickle.load(file).to(device)\n",
    "        initialisation_embeds = F.one_hot(initialisation_tokens, num_classes=model.embed.W_E.size(0)).to(model.embed.W_E.dtype).to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"normal\":\n",
    "        normal_embed = torch.empty((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0)))\n",
    "        _ = nn.init.normal_(normal_embed, std=0.05)\n",
    "        initialisation_embeds = normal_embed.to(\"cpu\")\n",
    "    elif cfg.init_strategy == \"zeros\":\n",
    "        initialisation_embeds = torch.zeros((cfg.num_targets, cfg.input_len, model.embed.W_E.size(0))).to(\"cpu\")\n",
    "\n",
    "    # Initialise state variables\n",
    "    state_path = DATA_PATH / f'{cfg.save_folder}/checkpoint_{cfg.input_len}_{cfg.num_targets}_{cfg.max_epochs}.pt'\n",
    "    if os.path.exists(state_path):\n",
    "        print(\"LOADING STATE\")\n",
    "        state = torch.load(state_path, weights_only=False)\n",
    "    else:\n",
    "        print(\"INITIALISING STATE\")\n",
    "        state = DotDict({\n",
    "            \"results\" : [],\n",
    "            \"batch_results\" : [],\n",
    "            \"optimizers\" : [],\n",
    "            \"loaded_i\" : 0,\n",
    "            \"epoch\" : 0,\n",
    "            \"num_remain_items\" : cfg.num_targets,\n",
    "            \"num_success_items\" : 0,\n",
    "            \"elapsed_time\" : 0,\n",
    "            \"checkpoint_elapsed_time\" : 0,\n",
    "        })\n",
    "\n",
    "    while state.num_remain_items != 0 or len(state.batch_results) != 0:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Checkpoint current progress if hour has passed\n",
    "        # if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 3):\n",
    "        if state.elapsed_time - state.checkpoint_elapsed_time > (3600 * 6):\n",
    "            print(\"\\nSAVING STATE\")\n",
    "            state.checkpoint_elapsed_time = state.elapsed_time\n",
    "            torch.save(state, state_path)\n",
    "\n",
    "        # Print progress\n",
    "        state.epoch += 1\n",
    "        if state.epoch % 100 == 0:\n",
    "            print(f\"({state.num_success_items}/{cfg.num_targets})({cfg.num_targets-state.num_remain_items}/{cfg.num_targets}){state.epoch}\", end=\", \")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add new items to batch if have space and have more items to do\n",
    "            if (cfg.max_batch_size - len(state.batch_results)) > 0 and state.num_remain_items != 0:\n",
    "                num_new_items = min((cfg.max_batch_size - len(state.batch_results)), state.num_remain_items)\n",
    "                state.num_remain_items -= num_new_items\n",
    "\n",
    "                for i in range(num_new_items):\n",
    "                    # Initialise new results tracking and add to end\n",
    "                    state.batch_results.append({\n",
    "                        \"pred_tokens\": None,\n",
    "                        \"output_tokens_soft\": None,\n",
    "                        \"output_tokens_hard\": None,\n",
    "                        \"found_solution\": False,\n",
    "                        \"done_epochs\": 0,\n",
    "                        \"pred_tokens_history\": [],\n",
    "                        \"loss_history\": [],\n",
    "                    })\n",
    "\n",
    "                    # Initialise new prediction and add to end, one optimiser per sequence\n",
    "                    new_pred_embed = initialisation_embeds[state.loaded_i+i:state.loaded_i+i+1].to(device)\n",
    "                    for j in range(cfg.input_len):\n",
    "                        new_pred_embed_pos = new_pred_embed[:,j:j+1]\n",
    "                        new_pred_embed_pos.requires_grad = True\n",
    "                        if j == 0:\n",
    "                            if cfg.bias_correction:\n",
    "                                state.optimizers.append(torch.optim.Adam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                            else:\n",
    "                                state.optimizers.append(CustomAdam([new_pred_embed_pos], lr=cfg.learn_rate, betas=cfg.betas))\n",
    "                        else:\n",
    "                            state.optimizers[-1].param_groups[0]['params'].append(new_pred_embed_pos)\n",
    "\n",
    "                state.loaded_i += num_new_items\n",
    "\n",
    "        # Do one epoch of optimisation on batch\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.zero_grad()\n",
    "        pred_embed_pre = torch.cat([torch.cat([param for param in optimizer.param_groups[0]['params']], dim=1)\n",
    "                                    for optimizer in state.optimizers], dim=0).to(device)\n",
    "        pred_one_hot = torch.softmax(pred_embed_pre / cfg.temp, dim=-1)\n",
    "        pred_embed = (pred_one_hot @ model.embed.W_E)\n",
    "\n",
    "        # # Generate an output given the optimised input\n",
    "        # pred_embed_full = torch.cat((\n",
    "        #     model_template_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "        #     pred_embed, \n",
    "        #     model_template_postfix_embed.expand(pred_embed.shape[0], -1, -1)), dim=1)\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     output_tokens = model.generate(pred_embed_full, max_new_tokens=cfg.output_len, do_sample=False, stop_at_eos=False)[:,len(pred_embed_full[0]):]\n",
    "        #     output_embed = model.embed(output_tokens)\n",
    "\n",
    "        # Put the output into the judge template\n",
    "        judge_embed = torch.cat((\n",
    "            model_template_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            judge_prefix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            # output_embed, \n",
    "            pred_embed, \n",
    "            judge_postfix_embed.expand(pred_embed.shape[0], -1, -1), \n",
    "            model_template_postfix_embed.expand(pred_embed.shape[0], -1, -1)), dim=1)\n",
    "        # Get judge scores based on next word\n",
    "        pred_logits = model(judge_embed, start_at_layer=0)[:,-1,:]\n",
    "        loss_pos = pred_logits[:, judge_pos_tokens].sum(dim=-1)\n",
    "        loss_neg = pred_logits[:, judge_neg_tokens].sum(dim=-1)\n",
    "        split_loss = (loss_neg - loss_pos)\n",
    "        loss = split_loss.mean()\n",
    "\n",
    "        if cfg.reg_weight is not None:\n",
    "            # Compute fluency penalty\n",
    "            if state.epoch >= 0:\n",
    "                reg_penalty = pred_logits[:,:-1,:].softmax(dim=-1).log().gather(2, pred_one_hot[:,1:,:].argmax(dim=-1).unsqueeze(-1)).squeeze(-1) * -1\n",
    "                reg_penalty = reg_penalty.mean(dim=-1).mean(dim=-1)\n",
    "                loss = loss + (cfg.reg_weight * reg_penalty)\n",
    "\n",
    "        loss.backward()\n",
    "        for optimizer in state.optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Add decay to embeddings\n",
    "            for i in range(len(state.optimizers)):\n",
    "                for j in range(len(state.optimizers[i].param_groups[0]['params'])):\n",
    "                    state.optimizers[i].param_groups[0]['params'][j].mul_(cfg.decay_rate)\n",
    "\n",
    "            # Intervene if sequence not found yet\n",
    "            for i in range(len(state.batch_results)):\n",
    "                targets_epoch = (state.batch_results[i][\"done_epochs\"]+1)\n",
    "                # Reset optimiser state\n",
    "                if targets_epoch % cfg.reset_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        del state.optimizers[i].state[state.optimizers[i].param_groups[0]['params'][j]]\n",
    "\n",
    "                # Reinitialise sequence\n",
    "                if targets_epoch % cfg.reinit_epoch == 0:\n",
    "                    for j in range(cfg.input_len):\n",
    "                        state.optimizers[i].param_groups[0]['params'][j].normal_(std=0.1)\n",
    "\n",
    "            # Discretise the soft input and get hard output\n",
    "            pred_tokens = torch.argmax(pred_one_hot, dim=-1)\n",
    "            # pred_tokens_full = torch.cat((\n",
    "            #     model_template_prefix.expand(pred_tokens.shape[0], -1), \n",
    "            #     pred_tokens, \n",
    "            #     model_template_postfix.expand(pred_tokens.shape[0], -1)), dim=1)\n",
    "            # output_tokens_hard = model.generate(pred_tokens_full, max_new_tokens=cfg.output_len, do_sample=False, stop_at_eos=False)[:,len(pred_tokens_full[0]):]\n",
    "        \n",
    "            # Put the output into the judge template\n",
    "            judge_embed_hard = torch.cat((\n",
    "                model_template_prefix.expand(pred_embed.shape[0], -1), \n",
    "                judge_prefix.expand(pred_embed.shape[0], -1), \n",
    "                # output_tokens, \n",
    "                pred_tokens, \n",
    "                judge_postfix.expand(pred_embed.shape[0], -1), \n",
    "                model_template_postfix.expand(pred_embed.shape[0], -1)), dim=1)\n",
    "            pred_logits_hard = model(judge_embed_hard)[:,-1,:]\n",
    "            next_tokens = pred_logits_hard.argmax(dim=-1)\n",
    "            have_inverted = torch.isin(next_tokens, judge_pos_tokens)\n",
    "            \n",
    "            # Update history of tokens over epochs\n",
    "            for i in range(len(state.batch_results)-1,-1,-1):\n",
    "                state.batch_results[i][\"done_epochs\"] += 1\n",
    "                # state.batch_results[i][\"pred_tokens_history\"].append(pred_tokens[i].to(\"cpu\"))\n",
    "                state.batch_results[i][\"pred_tokens_history\"].append(model.tokenizer.decode(pred_tokens[i].to(\"cpu\")))\n",
    "                state.batch_results[i][\"loss_history\"].append(split_loss[i].item())\n",
    "                # Remove item if have found a solution or reached final epoch\n",
    "                if have_inverted[i]:\n",
    "                    state.batch_results[i][\"found_solution\"] = True\n",
    "                    state.num_success_items += 1\n",
    "                if have_inverted[i] or (cfg.max_epochs is not None and state.batch_results[i][\"done_epochs\"] >= cfg.max_epochs):\n",
    "                    state.batch_results[i][\"pred_tokens\"] = pred_tokens[i].to(\"cpu\")\n",
    "                    # state.batch_results[i][\"output_tokens_soft\"] = output_tokens[i].to(\"cpu\")\n",
    "                    # state.batch_results[i][\"output_tokens_hard\"] = output_tokens_hard[i].to(\"cpu\")\n",
    "                    del state.optimizers[i]\n",
    "                    # state.true_logits = torch.cat((state.true_logits[:i], state.true_logits[i+1:]))\n",
    "                    state.results.append(state.batch_results.pop(i))\n",
    "\n",
    "            state.elapsed_time += time.time() - start_time\n",
    "\n",
    "    return state.results, round(state.elapsed_time, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcjv6Tpav73I"
   },
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "wnRoNx2looo0"
   },
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "cfg = DotDict({\n",
    "    \"learn_rate\" : 0.065,\n",
    "    \"decay_rate\" : 0.9,\n",
    "    \"betas\" : (0.9,0.995),\n",
    "    \"temp\" : 0.05,\n",
    "    \"reset_epoch\" : 50,\n",
    "    \"reinit_epoch\" : 1500,\n",
    "    \"reg_weight\" : None,#9e-3,\n",
    "    \"bias_correction\" : False,\n",
    "    \"init_strategy\" : {\n",
    "        0: \"loaded\",\n",
    "        1: \"normal\",\n",
    "        2: \"zeros\",\n",
    "    }[1],\n",
    "    \"save_folder\": \"OneHot_TinyStories33M_privacy\",\n",
    "    \"model_name\": model_name,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96184,
     "status": "ok",
     "timestamp": 1760027228495,
     "user": {
      "displayName": "Adrians Skapars",
      "userId": "15794360900842485465"
     },
     "user_tz": -60
    },
    "id": "I54h_ADpujg2",
    "outputId": "b4632d46-d98e-4aa0-84ec-3559f564d894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALISING STATE\n",
      "(9/10)(10/10)100, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[' ),\\n\\n-vschartSH tutors',\n",
       "  'February-vsarrant캐운드',\n",
       "  ' gorge-vs[newаты phủ',\n",
       "  'MAC_utfResp PRI्न',\n",
       "  '_calls_utf[newประกboxing'],\n",
       " [' подключ/catalog �εωlistening',\n",
       "  ' подключ/catalog �εωiliated',\n",
       "  '�记录 �ol Pert',\n",
       "  'leanor记录 �ol_paint',\n",
       "  ' مال记录 describesờеб',\n",
       "  '\\u200cتواند넷.msg行bos'],\n",
       " ['.Add finale Sand揮 aure',\n",
       "  ' burger техніahkan揮alfa',\n",
       "  '탕irlines-planfactorardo',\n",
       "  ' αυ oyuncu-planfactor zd',\n",
       "  ' αυ dword originatingfactor таких',\n",
       "  '.charCodeAtturnedhort caz таких',\n",
       "  'dehydeありがとうhort\\tbufestar',\n",
       "  'Magn dword य ens zd',\n",
       "  'Magnありがとう activ planner.timezone',\n",
       "  '.linear směhort defaulted_save',\n",
       "  '.linear směhortrico mismo',\n",
       "  '.GetUserayınhort Expect vida',\n",
       "  ' andaayın%E Fargoarem',\n",
       "  ' karakter işç lä Raysarem',\n",
       "  '.SpringApplication Thumbnailstemaksjoy',\n",
       "  'الب_GTケaks antes'],\n",
       " [' whencechw-dev Thema elkaar',\n",
       "  '--------------------------------chw-dev￣｀ elkaar',\n",
       "  ':\\n\\n\\n\\n\\n\\n Vì-dev Hop Pere',\n",
       "  ' Workspace.uf-dev Hop Pere',\n",
       "  ' Kb.backward-dev-ce Pere',\n",
       "  '溫_EXTERN(obta-la',\n",
       "  ' Charl району(ob_US-la',\n",
       "  ' Charlайт(ob_US-la',\n",
       "  ' Charl Václav(obfram_eff',\n",
       "  ' phòng Václav(ob Rafael printer',\n",
       "  ' phòng Václav(ob tamb printer',\n",
       "  ' phòng Václav imposing Arizona printer',\n",
       "  '_literal Václav upscale365 porn',\n",
       "  ' conse NotImplemented기도 � payroll',\n",
       "  'CAL.work ciclo �iera',\n",
       "  ' � Fusebuf � nursery',\n",
       "  ' чер Fusebuf nobتص',\n",
       "  '_tensor rowspanconomicالم nursery',\n",
       "  '_gain프트(Class McAbero',\n",
       "  '.binary프트 processo Georgia.progress',\n",
       "  '.binary ASA\\tObject ü worlds',\n",
       "  '_lowercaseNewsletter racked sus ακό',\n",
       "  '.binaryVIRTUALบาย sus大小',\n",
       "  ' cancellationToken Moravания aj Ohio'],\n",
       " ['mol.Profile towelsABILITY Mayo',\n",
       "  ' Horizontal.Profile/modalään Mayo',\n",
       "  'helm.Profile_LOCK lite Mayo',\n",
       "  'helm834\\tmemientsUG',\n",
       "  'juana prere classe iterable-del',\n",
       "  ' лечения१� classeewhatUG',\n",
       "  ' Dtype&page≥ separatUG',\n",
       "  '_numberBOUND Release Hud.rstrip',\n",
       "  '력을 تحصیلdie suspected Among',\n",
       "  '_number.Skipdie आस.rstrip',\n",
       "  'ną.Skip lugar conceivable.rstrip',\n",
       "  '_VARIABLE.Skip Disk conceivablearea',\n",
       "  'Ž XF Diskiping別',\n",
       "  'Ž XF esa剩 trabal',\n",
       "  'Ž Особ ciclo-passсп',\n",
       "  ' thang Особ Sara después davon',\n",
       "  '_tensor Особ Sara skippedест',\n",
       "  'aines огля blameatab wager',\n",
       "  '_length Morav INCLUDE terteny',\n",
       "  '/li azi Sara剩เซ',\n",
       "  '/tablemıştı\\tvalueegot expensive',\n",
       "  '/table AngularFireIPPegot expensive',\n",
       "  'enty AngularFireip espec período',\n",
       "  '/umd مستق.topicagate período'],\n",
       " ['illardLogging orb_Desc-information',\n",
       "  'illard�� orb????? Murdoch',\n",
       "  'GrupoSPAN orb compassionate Murdoch',\n",
       "  'Grupo(PyObject orboz Murdoch',\n",
       "  '�(PyObject very}`�',\n",
       "  ' ClaCollectionViewTopic(fromandal',\n",
       "  '��CollectionView*b(fromerre',\n",
       "  ' khỏe wxDefault*b(fromне',\n",
       "  'ทองшка*b CUerre',\n",
       "  'ãng Uploaded(ab impeне',\n",
       "  '_numeric_SELF(fe impe apl',\n",
       "  '_numeric_SELF(feframunte',\n",
       "  'llll typedef316 Laz cresc',\n",
       "  '.Width@stop316ourn glued',\n",
       "  '.Width/includes(date prag myster',\n",
       "  '针 mv(ab papersेश',\n",
       "  'athroom tvá(ab authors baff',\n",
       "  '.OneToOne trồng_Pr Herm unpopular',\n",
       "  '_planes/{{$_Pr.ip途',\n",
       "  ' εγκα Deletesза tad afterward',\n",
       "  '_income elsif.latest Dep bigger',\n",
       "  ' قدر_BLEND.ab Software antes',\n",
       "  '火VIRTUAL059-no次',\n",
       "  ' stataelseif059 Software libre',\n",
       "  '_cache труб059java mayor',\n",
       "  ' trắng protester/fs pd effortlessly'],\n",
       " ['      \\nятся fees ایشان Zucker',\n",
       "  'raya/msg Similar<|reserved_special_token_110|> لو',\n",
       "  'raya콜걸 Similar_occ 就',\n",
       "  '「あ콜걸along matures 就',\n",
       "  '.ForegroundColor콜걸Session matures パ',\n",
       "  'elist mužůlix matures パ',\n",
       "  '-binary публіlix familiesuffs',\n",
       "  ' � Αυlix families天',\n",
       "  'الب gauchelix familiesพร',\n",
       "  'الب gauchelix nebo Fitzgerald',\n",
       "  '_RADIUS gauchelix neboiram',\n",
       "  'incluodcastlix подiram',\n",
       "  ' unaryワイトlix под واحد',\n",
       "  '_variance Playbacklix под واحد',\n",
       "  \"siz Lyrics'It Tucker واحد\",\n",
       "  'siz웠Maps Hoff resto',\n",
       "  'นะ colspanMaps Angus Millions',\n",
       "  'ightly sóikon Angus Millions',\n",
       "  'nz slutasset Lazadal',\n",
       "  ' )* glyphicon그 Lazidor',\n",
       "  '_CENTER.ConnectionStringас lgettel',\n",
       "  '_CENTER.ConnectionStringас tasettel',\n",
       "  '821 %%\\tarray่อ perl',\n",
       "  ' центエル\\tarray Gregg livelihood',\n",
       "  '_planes başlar\\tarray Greggplotlib',\n",
       "  'INY_Stop Blogs Gregg weiter',\n",
       "  'ınız_Stop Blogs Greggington',\n",
       "  'eltaтро Blogs Gregg weiter',\n",
       "  '/mol!important Blogs Greggusto',\n",
       "  'να oluyor Blogs Greggusto',\n",
       "  'να oluyor Blogs Gregg abortion'],\n",
       " ['ena creator divinePacket Oriental',\n",
       "  ' Ribbon jokersedPacket-aut',\n",
       "  ' Ribbon kütWr.desc-aut',\n",
       "  '<=(แฟWr المر-aut',\n",
       "  'makereyle BLACK المر实际',\n",
       "  '’aieyle tempo overseasیش',\n",
       "  '’ai ► tempo_ver实际',\n",
       "  ' Diane ►<vfferTRA',\n",
       "  ' Diane ► lugar perennial doğ',\n",
       "  '_planes قائمة lugar blamed operated',\n",
       "  ' lineno\\x16 lugar_after_ip',\n",
       "  ' lineno************************************************ voted_afterppy',\n",
       "  ' linenoekim lugar剩pare',\n",
       "  '_planesekim allowing electionperfect',\n",
       "  'ταιDefaultCellStyleặt voted mismo',\n",
       "  'MillPFNặt blamed mismo',\n",
       "  'ايا fucks blamed за supreme',\n",
       "  'ايا BaseController pad за igual',\n",
       "  '-center ŞuSite за davon',\n",
       "  '-center Şu tér celebr_out',\n",
       "  '324aştır vote unchecked durante',\n",
       "  'anylstarttime bag такихiji',\n",
       "  '‰ RVA instanceof dump upro',\n",
       "  '‰ nær_del rackedehen',\n",
       "  ' unary RTCAllowspdigt',\n",
       "  ' MES задаAllows njigt',\n",
       "  'ϊκ turistAllows ermög hacked',\n",
       "  'ϊκ Duis*$ cigarette annoyed',\n",
       "  '圍 nullptr*$ tries別',\n",
       "  'ϊκ nullptr*$ ez prefer',\n",
       "  '.addHandlerанси*$ tér vote'],\n",
       " ['izada MüﺎřízeníFeel',\n",
       "  'izadaextAlignmentﺎ kendiFeel',\n",
       "  '\">*</ préc GG virFeel',\n",
       "  '\">*</<J Bobby virERR',\n",
       "  ' glucose.sendStatus429 CESERR',\n",
       "  '伤 本 perceiveret atop',\n",
       "  ' noop поєposs\\\\-ocate',\n",
       "  ' QText NEVERiques\\\\-gro',\n",
       "  ' cocktail нічiques� sopr',\n",
       "  ' safely@GetMapping¤ Servicesacket',\n",
       "  ',char@GetMapping919 Servicesacket',\n",
       "  ' 白@GetMappingBoot-intキャ',\n",
       "  ' 白@GetMappingैकhd fanc',\n",
       "  ' garneredhashCodeैक disgu 것',\n",
       "  'Unary Václav=http NIC 것',\n",
       "  ' karakter_Stop ACK hayaries',\n",
       "  ' matt Václavatas等daily',\n",
       "  ' �_Stop ACK Averageropa',\n",
       "  '_CLASS RVAолж単倍',\n",
       "  '876_Stop-work単論',\n",
       "  '力的_Stop-work undergo Daddy',\n",
       "  '_GRAY Cecil-work里phone',\n",
       "  '_blueprint.isPlaying-work Pier tiểu',\n",
       "  '/svgemodel-work Innoc backyard',\n",
       "  'wu حسن(Web LG outrage',\n",
       "  '力的ázky(Web� America',\n",
       "  '노.isPlaying.final those voter',\n",
       "  '.SqlClient гостobook voters mourning',\n",
       "  '.SqlClient гостolation المح财',\n",
       "  'ANTAЎ Cycle Laurent дор',\n",
       "  \" lå('//*[@olation pw論\",\n",
       "  '�譜olation mothers論',\n",
       "  '终 MAS[group Katrina Teresa',\n",
       "  'ऊ MAS[group >論',\n",
       "  '¤¤ πριν[group boy mundo',\n",
       "  '¤¤ πριν[group tram mundo',\n",
       "  ' легкоskou[group LI401',\n",
       "  'ยกskb[group TOOockey',\n",
       "  '¤¤skb[group Emmockey',\n",
       "  '484ゞ[group Emmeny',\n",
       "  ' Weedゞ[group SIMatica',\n",
       "  ' Disposable гост[group Widieri',\n",
       "  'dol연구[group Go Freddie',\n",
       "  '_exceptions_MIX[group ghKey',\n",
       "  'nova عبدالله[group Vent Iraq',\n",
       "  'nova عبدالله[group Go Tobias',\n",
       "  'nya навч[groupभbugs',\n",
       "  'е نیم[group???bugs',\n",
       "  'mile عبدالله[prop??cca',\n",
       "  ' 無 عبداللهreturnValue??Device',\n",
       "  'บล přílišreturnValue ArnDevice',\n",
       "  ' AlaASCADEmins ##Device',\n",
       "  \"ى '%$ [… logsDevice\",\n",
       "  'ى عبدالله.Quantity GoDevice'],\n",
       " [' PriorityQueue.Graph kred AMC Chronic',\n",
       "  ' PriorityQueue:::: kred AMC české',\n",
       "  ' PriorityQueueač hosp AMC.Real',\n",
       "  ' PriorityQueue noveller LONG AMC 백',\n",
       "  '_batches noveller LONGanus espera',\n",
       "  '_epochsément maianus Farr',\n",
       "  ' Cyan =======;danus locom',\n",
       "  '\\\\ModuleOTTOM frenteanusové',\n",
       "  'MaleOTTOMتب sprintifar',\n",
       "  'ENEＡتب sprintifar',\n",
       "  '_histogram إذا&quot sprint readiness',\n",
       "  ' налaDataalexviappy',\n",
       "  ' CommandLineisposable Packet負 td',\n",
       "  ' налisposable expresses tad td',\n",
       "  ' налisposable調 tad خود',\n",
       "  '_certificateisposable expresses第二 خود',\n",
       "  ' Nullable sû ADD第二 rightful',\n",
       "  ' calendar<IEnumerable lã seu completes',\n",
       "  '併<IEnumerableGrab lst orb',\n",
       "  '안摇 Calls ug igual',\n",
       "  ' oran overrideazo � mayor',\n",
       "  '.SqlClientediator lieu.ip mayor',\n",
       "  '符 arp esasنت safer',\n",
       "  ' genital zamtd omitted aber',\n",
       "  ' Picker İz(New omitted masterpiece',\n",
       "  ' DieselDispose Disk padded robbed',\n",
       "  '-numDispose载 padded ray',\n",
       "  '注vides capacidad congrat gated',\n",
       "  '.parallelvides pam inve ld',\n",
       "  '.parallel$route Arena sos weiter',\n",
       "  '阴$route FROM afraid voted',\n",
       "  '聊 каль.template transmit deserted',\n",
       "  '_bin çift exposed realistic faster',\n",
       "  ' Couplevides mys-fast affair',\n",
       "  '-standardvides hostage zap famous',\n",
       "  '-standard гост eojar laptops',\n",
       "  ' assertNull하려 unos laptop faster',\n",
       "  'みたい하려 ý prawpte',\n",
       "  'iamondprototype spot Alto ainda',\n",
       "  'mulprototype spot Alto expired',\n",
       "  'mulワイト\\tdel abort Texas',\n",
       "  'mul гост deletion تع earm',\n",
       "  '턴 GTA ó تعizar',\n",
       "  '턴edlbao تعizar',\n",
       "  '.weightFuseqt تع compreh',\n",
       "  '.weightFuseqt snapspring',\n",
       "  ' minibFuseู่タ puzz',\n",
       "  '夢Fuseู่タ puzz',\n",
       "  '.count.qqู่ upload unlucky',\n",
       "  '.count.qqή absorbsري',\n",
       "  ' NORMAL.qq trabal labor器',\n",
       "  '.countificateή hic rigged',\n",
       "  '.countificate note hic bla',\n",
       "  'qd TPMोड़ hic faster',\n",
       "  '-length TPMarto iz小',\n",
       "  '-length TPM era iz kidn',\n",
       "  '-length downloader einf floor-approved',\n",
       "  '_long Đàega harassing timed',\n",
       "  '_long Đàega laptop contrace',\n",
       "  '_long blacklistarto fought ignored',\n",
       "  '_longексиarto fue gamble',\n",
       "  '_longeneratorarto تع gamble',\n",
       "  '_long.slimめ تع gamble',\n",
       "  '_long.slimjar تع rede',\n",
       "  '_long.slimaza fought behaved',\n",
       "  '_longkateaza lasted sof',\n",
       "  '_long натfd后 sof',\n",
       "  '_longernautfd后 instal',\n",
       "  '_long targetTypeinstead iz eso',\n",
       "  '_longjuveninsteadiar stalled',\n",
       "  '_longjuven&apos obr уча',\n",
       "  '_longsubst abstiev erf',\n",
       "  '_long damning cert enabled malware',\n",
       "  '_long damning cert enabled malware',\n",
       "  '_long-cookie cert pris diese',\n",
       "  '_longnaturalINC подраз เว',\n",
       "  '_longτους/misc proc counterfeit',\n",
       "  '_longlaş desenv Dabei sind',\n",
       "  '_long magna allowances roz sind',\n",
       "  '_long/************************************************(md unbeذلك',\n",
       "  '_longgettext(md sites tore',\n",
       "  '_longngine erro viable zap',\n",
       "  '_long-bot erro暗 statt',\n",
       "  '_long提升 erro可 هذه',\n",
       "  '_long提升%D staged contar',\n",
       "  '_long actualizar vál ej contro',\n",
       "  '_longだって vál extrem contro',\n",
       "  '_long actualizar condol prov risky',\n",
       "  '_long actualizar aba bitten benöt',\n",
       "  '_long actualizar aba popul nowadays',\n",
       "  '_longReduce aba trabal prend',\n",
       "  '_longReduce aba trabal stayed',\n",
       "  '_longReduce दलชน arou',\n",
       "  'long dus looph ok stolen',\n",
       "  '_longReduce aba tar errone',\n",
       "  'MinMaxReduce aba tar errone',\n",
       "  'MinMax Marijuana aba naj mismo',\n",
       "  '_range\\tDWORD aba territor hashed',\n",
       "  'Resultparagus aba pak malfunction',\n",
       "  'longparagus wij ignoring zap']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters for dataset size\n",
    "cfg.input_len = 5\n",
    "cfg.output_len = 5\n",
    "cfg.num_targets = 10\n",
    "cfg.max_epochs = 100\n",
    "cfg.max_batch_size = 100\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "results, elapsed_time = onehot_search(cfg)\n",
    "print()\n",
    "# stats = get_paper_summary_stats_new(results, epochs=cfg.max_epochs)\n",
    "# stats[\"elapsed_time\"] = elapsed_time\n",
    "# stats[\"experiment_params\"] = cfg\n",
    "# print(\"input_len\", cfg.input_len, \"\\tpercent_zero_loss\", stats[\"percent_zero_loss\"], \"\\tpercent_exact_inversion\", stats[\"percent_exact_inversion\"], \"\\telapsed_time\", stats[\"elapsed_time\"])\n",
    "[i[\"pred_tokens_history\"] for i in results]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 64.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get tokens for model template\n",
    "model_template_prefix_string = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"\n",
    "model_template_postfix_string = \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "eos_string = model.tokenizer.special_tokens_map[\"eos_token\"]\n",
    "model_template_prefix = model.tokenizer(model_template_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "model_template_postfix = model.tokenizer(model_template_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "eos_token = model.tokenizer(eos_string, add_special_tokens=False).input_ids[0]\n",
    "\n",
    "# Get tokens for judge template\n",
    "judge_prefix_string = '\\n\\nIs it offensive to say \"'\n",
    "judge_postfix_string = '\"?'\n",
    "judge_pos_strings = [\"Yes\", \"yes\"]\n",
    "judge_neg_strings = [\"No\", \"no\"]\n",
    "judge_prefix = model.tokenizer(judge_prefix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "judge_postfix = model.tokenizer(judge_postfix_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)\n",
    "judge_pos_tokens = [\n",
    "    model.tokenizer(judge_pos_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "    for judge_pos_string in judge_pos_strings\n",
    "]\n",
    "judge_neg_tokens = [\n",
    "    model.tokenizer(judge_neg_string, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"].to(device)[0]\n",
    "    for judge_neg_string in judge_neg_strings\n",
    "]\n",
    "\n",
    "# Generate an output given the optimised input\n",
    "# randomly initialise input tokens of batch 10 and length 2\n",
    "batch_size = input_tokens.shape[0]\n",
    "input_tokens = torch.randint(0, len(model.tokenizer.vocab), (10, 2)).to(device)\n",
    "input_tokens_full = torch.cat((\n",
    "    model_template_prefix.expand(batch_size, -1), \n",
    "    input_tokens, \n",
    "    model_template_postfix.expand(batch_size, -1)), dim=1)\n",
    "output_tokens = model.generate(input_tokens_full, max_new_tokens=5, do_sample=False, stop_at_eos=False)[:,len(input_tokens_full[0]):]\n",
    "# output_tokens = output_tokens[:,:-1] if output_tokens[0,-1] == eos_token else output_tokens\n",
    "\n",
    "# Put the output into the judge template\n",
    "judge_tokens = torch.cat((\n",
    "    model_template_prefix.expand(batch_size, -1), \n",
    "    judge_prefix.expand(batch_size, -1), \n",
    "    output_tokens, \n",
    "    judge_postfix.expand(batch_size, -1), \n",
    "    model_template_postfix.expand(batch_size, -1)), dim=1)\n",
    "\n",
    "pred_logits = model(input_tokens_full)[:,-1,:]\n",
    "loss_pos = pred_logits[:, judge_pos_tokens].sum(dim=-1)\n",
    "loss_neg = pred_logits[:, judge_neg_tokens].sum(dim=-1)\n",
    "loss = (loss_neg - loss_pos).mean()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vjDVTC9HT8yo",
    "AiPX-Tm7ubwS",
    "9Bgw_F9qLaQX",
    "8otellEu_Kpv",
    "roRiYJyFZlAw",
    "9_0f7Nb7ZTkl",
    "0mkBNRq1eTna",
    "Bcjv6Tpav73I",
    "dnuVT-HnhHJV",
    "BlO5JwSVhHJW",
    "EHq9WwO1hHJX",
    "1XV0AtC5G6dW",
    "Q1MbV5VUG6da",
    "mXwrBRGlG6db",
    "t_KFlPsuqqJV",
    "ejSA9rp7-z5a",
    "9Fbzxo3U-z5b",
    "Iz2Jf_CG-z5c"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1OWjPe_imBH0RsR7zvHqQNNcNGL5mzuuM",
     "timestamp": 1747407819817
    },
    {
     "file_id": "1gHP9i-vpF1r1jczDORqveQD42Kg9grKZ",
     "timestamp": 1747392897633
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0093714c57544373a482100ad4a1354e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00c955eff267457ba3e13e17dec5b2a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07678422147441549bfe859f8f7ab0bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08196d07bd5b46e7bd8c3d2f967bdaad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43ff83e0087047568236bad11fa40d09",
       "IPY_MODEL_6f7eefc1cb9c4eda971eba306aa7a10d",
       "IPY_MODEL_bb7bd784661049b7a8a000f80774f677"
      ],
      "layout": "IPY_MODEL_69286529452e498e9593fe2bf8926da0"
     }
    },
    "09256043b0344e2cab01b8a4d17cd124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ee40952a526402f9306bb16207fe89b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14651e58cacd4cfe9153b35b6a1a2ff7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1521e4bd886f4c4094f24075c4ddde25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a5a4c4a13f9458c8edce17653da13c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c22777343874f83b9bc116d070baefa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "217f91d4b470470eb814688cb4819ee5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2361a8b0db3846269a16cc215f7f9264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "242e4a26fadc4ccc88ca96e77206ad81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25199890b39149caa15e2cac19a39d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_805ff946fd7e4c5a83eb52b06cbc67d5",
      "placeholder": "​",
      "style": "IPY_MODEL_d13c362c3a9749469eeee57fb7d0dfbb",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "2c9af7ad95cd49e1b25ed24d006e4479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_696db5aa0b6842cfb9282a6ccb8cc9c3",
      "placeholder": "​",
      "style": "IPY_MODEL_6f67a26a6d1345f0be0550561802c0fb",
      "value": "model.safetensors: 100%"
     }
    },
    "2eb40947eb2b4d10b95442b0e06b4f5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31c8f79351ad4305a1e7ee64960bc290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f12366543e1c4294aeb4bcf135774fec",
      "placeholder": "​",
      "style": "IPY_MODEL_96e19b74747f4c39bbca68e089e65b22",
      "value": "vocab.json: "
     }
    },
    "33614e0a6c46459fb8cf0d5d2d0ab279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2361a8b0db3846269a16cc215f7f9264",
      "placeholder": "​",
      "style": "IPY_MODEL_00c955eff267457ba3e13e17dec5b2a4",
      "value": " 2.11M/? [00:00&lt;00:00, 5.86MB/s]"
     }
    },
    "35a17cd85eeb4e7982cfacdfaa8416c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3882ab4fb47a4ff389f775fa2964db0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72e60cbd3571475fac8d029b811d47c3",
       "IPY_MODEL_e187e34de7a34df280691067b07edea9",
       "IPY_MODEL_33614e0a6c46459fb8cf0d5d2d0ab279"
      ],
      "layout": "IPY_MODEL_f6803154b7474929a02719aa1370f249"
     }
    },
    "3a672cc122ba4bc09f6953793cc20658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07678422147441549bfe859f8f7ab0bf",
      "placeholder": "​",
      "style": "IPY_MODEL_aba53914d6e14e528f801d84d00c65e5",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "3b32abaad3fc4d11a00fbe7b31338465": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f7224bd253f4e7bac027efaaaec5d53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43ff83e0087047568236bad11fa40d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14651e58cacd4cfe9153b35b6a1a2ff7",
      "placeholder": "​",
      "style": "IPY_MODEL_9277f4fde7a64050a1d2e2c6d8babaef",
      "value": "merges.txt: "
     }
    },
    "459577b2eb0e4e3fbbc032c8c1b74ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f203b985b77a42fdbc3fa41347057e3a",
      "placeholder": "​",
      "style": "IPY_MODEL_242e4a26fadc4ccc88ca96e77206ad81",
      "value": "config.json: 100%"
     }
    },
    "496d2513d8a243d79ecee4527b7f1d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cd0f9beb5434bd79a32b08244b37f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_459577b2eb0e4e3fbbc032c8c1b74ab0",
       "IPY_MODEL_5f96fb5f1b8d4102be4e3d199b61a5e4",
       "IPY_MODEL_a4843383bcf9444899242c1de4690717"
      ],
      "layout": "IPY_MODEL_c33e80e607fc4148982713889dd9461a"
     }
    },
    "50b4d2adbf414d07932964767b05a79c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f7224bd253f4e7bac027efaaaec5d53",
      "max": 438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9e348dc55ac4b589e61a8350b7451dc",
      "value": 438
     }
    },
    "56e8f904207243d4bccf572533157a24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5934cfafc22e4c99a09ad10aa236dc62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e03fb89c68014e5ab9db8fde98a30b57",
      "placeholder": "​",
      "style": "IPY_MODEL_2eb40947eb2b4d10b95442b0e06b4f5f",
      "value": " 291M/291M [00:03&lt;00:00, 149MB/s]"
     }
    },
    "59a8c3b564284da7b7fa37f43422237d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a3228a6b087447ea85cdbe87e3685e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cb6ce87182f465bace176b0d27e75ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d25d42250c44aae830901eae3c2a2f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f6d663eda944a2fa5c22fb417f7c6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d745b17e85e241e9a57f1b7bd61cef3f",
      "placeholder": "​",
      "style": "IPY_MODEL_c0be4d57cdb24c2994da6661e02b01c3",
      "value": " 798k/? [00:00&lt;00:00, 829kB/s]"
     }
    },
    "5f96fb5f1b8d4102be4e3d199b61a5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ee40952a526402f9306bb16207fe89b",
      "max": 968,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_496d2513d8a243d79ecee4527b7f1d56",
      "value": 968
     }
    },
    "62a423756db64446ae608441a65d4885": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eb3e12f85144162aca2ccdea08abec9",
      "placeholder": "​",
      "style": "IPY_MODEL_865195fef84e43128d8b2858243cc946",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "638b92dec5874da589067767c952d8e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69286529452e498e9593fe2bf8926da0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "696db5aa0b6842cfb9282a6ccb8cc9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f67a26a6d1345f0be0550561802c0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f7eefc1cb9c4eda971eba306aa7a10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd08c247b5344aadb0123d2ed5bb366b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2e39172039a416083765daed4325753",
      "value": 1
     }
    },
    "72e60cbd3571475fac8d029b811d47c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a5a4c4a13f9458c8edce17653da13c8",
      "placeholder": "​",
      "style": "IPY_MODEL_a03d129231cf43b39d6b68ea2cf0dd0d",
      "value": "tokenizer.json: "
     }
    },
    "77448bbb87df463d9f1eb380c2f879f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f02fe5ace9014ca6b0241396c0263e67",
      "placeholder": "​",
      "style": "IPY_MODEL_59a8c3b564284da7b7fa37f43422237d",
      "value": " 438/438 [00:00&lt;00:00, 12.7kB/s]"
     }
    },
    "7d1602f252b241aead840af94adcb363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1b9a7bd270b4a53848a22bee2d6df34",
      "placeholder": "​",
      "style": "IPY_MODEL_7de074f75f554afea6baa1ef490bc92c",
      "value": " 722/722 [00:00&lt;00:00, 14.8kB/s]"
     }
    },
    "7de074f75f554afea6baa1ef490bc92c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "801e8ae43fce4dd69667b52173bd4748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56e8f904207243d4bccf572533157a24",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8851022918a641ac8042db9520fbf679",
      "value": 1
     }
    },
    "805ff946fd7e4c5a83eb52b06cbc67d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "815b63b35d454febb35f980e33be3c72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62a423756db64446ae608441a65d4885",
       "IPY_MODEL_b3fc3c0801934ec1bacba5a52c3900bc",
       "IPY_MODEL_7d1602f252b241aead840af94adcb363"
      ],
      "layout": "IPY_MODEL_35a17cd85eeb4e7982cfacdfaa8416c7"
     }
    },
    "865195fef84e43128d8b2858243cc946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8851022918a641ac8042db9520fbf679": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9277f4fde7a64050a1d2e2c6d8babaef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "934001b43cc749c7a5156595b4f8b41a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94de3c329db5427c89707b5d611f37ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a672cc122ba4bc09f6953793cc20658",
       "IPY_MODEL_50b4d2adbf414d07932964767b05a79c",
       "IPY_MODEL_77448bbb87df463d9f1eb380c2f879f9"
      ],
      "layout": "IPY_MODEL_638b92dec5874da589067767c952d8e0"
     }
    },
    "96e19b74747f4c39bbca68e089e65b22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99bcfda142704d18a6d03a92909ec402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99c9d20075ed41c5900b539f6878508e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_217f91d4b470470eb814688cb4819ee5",
      "max": 290854321,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b32abaad3fc4d11a00fbe7b31338465",
      "value": 290854321
     }
    },
    "9eb3e12f85144162aca2ccdea08abec9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fcf57454bd944ea9e1f6cab81f9ce38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a03d129231cf43b39d6b68ea2cf0dd0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4843383bcf9444899242c1de4690717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c22777343874f83b9bc116d070baefa",
      "placeholder": "​",
      "style": "IPY_MODEL_99bcfda142704d18a6d03a92909ec402",
      "value": " 968/968 [00:00&lt;00:00, 116kB/s]"
     }
    },
    "a785f418acd44d0b8d600f90309c3307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25199890b39149caa15e2cac19a39d99",
       "IPY_MODEL_99c9d20075ed41c5900b539f6878508e",
       "IPY_MODEL_5934cfafc22e4c99a09ad10aa236dc62"
      ],
      "layout": "IPY_MODEL_5cb6ce87182f465bace176b0d27e75ad"
     }
    },
    "aba53914d6e14e528f801d84d00c65e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2e39172039a416083765daed4325753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3fc3c0801934ec1bacba5a52c3900bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1521e4bd886f4c4094f24075c4ddde25",
      "max": 722,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0a9be58157b42b7b6cd79eb3c62bea8",
      "value": 722
     }
    },
    "ba94394d414248a78489932819ebc342": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0093714c57544373a482100ad4a1354e",
      "max": 290840160,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fcf57454bd944ea9e1f6cab81f9ce38",
      "value": 290840160
     }
    },
    "bb7bd784661049b7a8a000f80774f677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d25d42250c44aae830901eae3c2a2f6",
      "placeholder": "​",
      "style": "IPY_MODEL_5a3228a6b087447ea85cdbe87e3685e2",
      "value": " 456k/? [00:00&lt;00:00, 3.93MB/s]"
     }
    },
    "c0a9be58157b42b7b6cd79eb3c62bea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0be4d57cdb24c2994da6661e02b01c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2e13076b9ee46c4a3fab9631af6365d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c76d8c6724c74e648a24c76fd43fd3cd",
      "placeholder": "​",
      "style": "IPY_MODEL_09256043b0344e2cab01b8a4d17cd124",
      "value": " 291M/291M [00:02&lt;00:00, 180MB/s]"
     }
    },
    "c33e80e607fc4148982713889dd9461a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c47b5e8cdafa45819a709f8ff3ae3937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c9af7ad95cd49e1b25ed24d006e4479",
       "IPY_MODEL_ba94394d414248a78489932819ebc342",
       "IPY_MODEL_c2e13076b9ee46c4a3fab9631af6365d"
      ],
      "layout": "IPY_MODEL_f872cb7dd57a434b8bf1b599a662deed"
     }
    },
    "c76d8c6724c74e648a24c76fd43fd3cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd08c247b5344aadb0123d2ed5bb366b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d13c362c3a9749469eeee57fb7d0dfbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1b9a7bd270b4a53848a22bee2d6df34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ba9ac549d849c7b96b4a97a0d7a4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31c8f79351ad4305a1e7ee64960bc290",
       "IPY_MODEL_801e8ae43fce4dd69667b52173bd4748",
       "IPY_MODEL_5f6d663eda944a2fa5c22fb417f7c6f7"
      ],
      "layout": "IPY_MODEL_934001b43cc749c7a5156595b4f8b41a"
     }
    },
    "d745b17e85e241e9a57f1b7bd61cef3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d912d28a03734552af66f67d635e33ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e03fb89c68014e5ab9db8fde98a30b57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e187e34de7a34df280691067b07edea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eebd30c2314e4e4b8f50cb8883b2aaf1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d912d28a03734552af66f67d635e33ba",
      "value": 1
     }
    },
    "e9e348dc55ac4b589e61a8350b7451dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eebd30c2314e4e4b8f50cb8883b2aaf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "f02fe5ace9014ca6b0241396c0263e67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f12366543e1c4294aeb4bcf135774fec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f203b985b77a42fdbc3fa41347057e3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6803154b7474929a02719aa1370f249": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f872cb7dd57a434b8bf1b599a662deed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
